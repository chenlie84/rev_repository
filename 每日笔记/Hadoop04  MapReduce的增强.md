## Hadoop04  MapReduce的增强 

### 1.分区

1. #### mapreduce中的分区和reducetask的任务数

   1. 分区 partition 分区  ： 默认按照key2进行**hash**分区 ，按照一定的而业务逻辑 ， 将相同的数据交由一个 reduce进行任务处理

   2. reducetask任务数 ： 默认情况下 ， 只有一个reduce task ， 在分区的过程中， 尽量保持 和 分区数一致  可以大于和等于 绝对不能小于 否则会报错

   3. hashpartitioner是默认采用的分区

      ``` java
      return （key.hashCode() & Integer.MAX_VALUE） % numReduceTask ;
      
      // & 按位与运算符 1 & 1 = 1
                       1 & 0 = 0
      //保证正数
      
      ```

   4. ######  案例  彩票分区

      1. ###### 当k2有重复的时候 ，进行迭代

### 2.排序和序列化

1. 序列化 ： 将对象转换成字节流 进行数据传递

2. 反序列化 ：将字节流转换成对象 

3. java自带的序列化 过于

4. hadoop自带的两个序列化接口 ： 

   1. Writable：只是完成序列化操作
   2. WritableComparable ： 既有序列化操作又有两个对象之间的比较 

5. ###### 案例 ： 数据处理案例

   1. ###### 自定义排序

### 3.MapReduce中的计数器

1. 计数器：  用于任务执行过程中，记录任务的执行次数， 用于任务的跟踪
   1. 普通写法
   2. 枚举写法

### 4.规约 （combiner）

###### 规约 ： 在map端进行局部聚合 ， map端的reduce。

``` java
//没有自定义的Combiner类,需要继承reduce 
MyCombiner extends Reducer<k2 , v2 ,k2 ,v2> {   
}
```

### 5.综合练习 : 流量的统计

###### 需求 ： 按照手机号 ，统计上下行流量和 与 总和

``` java
//flowBean  , 将需要聚合的四个字段封装到flowbean中

//mapper ，切割手机号和流量 传递 手机号 与 封装好数据的flowbean

//reducer ， 对传递过来的K2 ，V2 进行聚合 ， 然后输出 

//main ， 执行RUN方法

```

###### 需求二 ：对上行流量进行升序排序

``` java
 // 排序必须是按照key2 进行排序 ， 
//所以key2不能是手机号，对四个字段进行排序， 封装到flowBean ，作为Key2
```

###### 需求三 ：手机号码分区

### 6.MapTask运行机制(*********)和并行度

1. **block** 物理储存

2. 读取文件完成的时候产生一个逻辑上的分片**Split** ， 一个分片对应一个MapTask

3. **Split计算方式**

   ``` java
   //默认情况下一个分片就是一个块大小
   
   //例外 130M 的文件
   //2 个块 ， 一个分片 （不是默认的）
   
   //原因 ：
   //如果最后一个块的小于块的10% ， 就按照一个分片来计算 ，避免资源的浪费 
   
   
   
   
   ```

4.  **Map任务的处理**

   ``` java
   //在Map任务中 ， 有一个collector用于收集处理完成的数据
   
   ```

5.  **环形缓冲区** （KV buffer） ： 默认大小是100M

   1. 写入数据的比例 ： 80%

      当Map端的数据写入到KvBuffer中达到80%的时候，会进行Spill（溢写）（从内存到磁盘）

      剩余的20%，会接着由Map端写入，当80% spill未完成 ， 但是20%已占满，此时会产生线程阻塞，此时会等待，溢写完成之后清空80%空间，再次写入。

6. 内存到磁盘的过程 （这是每次溢写的过程所作的）

   1. 分区 : 按照Key2hash分区
   2. 排序 ： 按照Key2进行字典排序
   3. 规约 ： 进行局部聚合

7. 溢写文件合并的过程 最多合并10个小文件，合并成一个大文件（Map端的临时文件）

### 7.ReduceTask的运行机制(*****

### *******)

1. **fetch** ： 开启线程 ，拉取Map端临时文件的数据 默认开启5个线程
2. **merge** ： reduce端的合并 ， 将多个小文件合并成大文件 ，合并的过程中会进行排序，**归并排序** ， 也会产生溢写，
   1. 合并文件有三种方式 ：
      1. 内存到内存 默认是不开启的
      2. 内存到磁盘  默认采用的方式
      3. 磁盘到磁盘****
3. **分组** ： 默认相同 的 key , Value聚合到一起
4. reducetask处理
5. hdfs保存

### 8.Shuffle过程(********)的数据压缩

为什么进行数据压缩：

1. Shuffle阶段的数据压缩 ： Map ---> Reduce
   1. 减少reduce端 拉取数据的时间，减少数据的处理的时间
2. Reduce数据处理完成
   1. 节省存储数据的空间

### 9.MapReduce中使用压缩 & Snappy

### 10.join链接 

1. map端的join   **相同的key的value聚合到一起**
2. reduce端的join